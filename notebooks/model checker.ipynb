{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import random\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as vutils\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "from torchsummary import summary\n",
    "\n",
    "import model_v4_small as model\n",
    "#import model\n",
    "\n",
    "import torch\n",
    "\n",
    "import keijzer_exogan as ke\n",
    "\n",
    "# initialize random seeds\n",
    "manualSeed = 999\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"} # Make sure the axis background of plots is white, this is usefull for the black theme in JupyterLab\n",
    "# Initialize default seaborn layout\n",
    "sns.set_palette(sns.hls_palette(8, l=.3, s=.8))\n",
    "sns.set(style='ticks')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Local variables\n",
    "\"\"\"\n",
    "workers = 0 # Number of workers for dataloader, 0 when to_vram is enabled\n",
    "batch_size = 1 # using one image ofcourse\n",
    "image_size = 32\n",
    "nz = 100 # size of latent vector\n",
    "n_iters = 1000 #25*10**3 # number of iterations to do for inpainting\n",
    "torch.backends.cudnn.benchmark=True # Uses udnn auto-tuner to find the best algorithm to use for your hardware, speeds up training by almost 50%\n",
    "\n",
    "lr = 1e-1\n",
    "lamb1 = 1 #1e4\n",
    "lamb2 = 1e-1 # 1 , total_loss = lamb1*loss_context + lamb2*loss_perceptual\n",
    "\n",
    "beta1 = 0.5 # Beta1 hyperparam for Adam optimizers\n",
    "selected_gpus = [0] # Number of GPUs available. Use 0 for CPU mode.\n",
    "\n",
    "#n_images = 500\n",
    "inpaint_n_times = 1\n",
    "\n",
    "save_array_results = False\n",
    "load_array_results = False\n",
    "filename = 'debug_0_100_1_1e-1_gan' # 0:100 lamb1=10, lamb2=1\n",
    "\n",
    "ngpu = len(selected_gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Load and setup models\n",
    "\"\"\"\n",
    "# Initialize cuda\n",
    "device = torch.device(\"cuda:\"+str(selected_gpus[0]) if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "\n",
    "# Load models, set to evaluation mode since training is not needed (this also allows batchsize 1 to work with batchnorm2d layers)\n",
    "netG = model.Generator(ngpu).eval().to(device)\n",
    "netD = model.Discriminator(ngpu).eval().to(device)\n",
    "\n",
    "# Apply weights\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "netG.apply(weights_init) # It's not clean/efficient to load these ones first, but it works.\n",
    "netD.apply(weights_init)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Define input training stuff (fancy this up)\n",
    "\"\"\"\n",
    "G = netG\n",
    "D = netD\n",
    "z = torch.randn(1, nz, 1, 1, requires_grad=True, device=device)\n",
    "\n",
    "# Handle multi-gpu if desired\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    G = nn.DataParallel(G, device_ids=selected_gpus, output_device=device)\n",
    "    D = nn.DataParallel(D, device_ids=selected_gpus, output_device=device)\n",
    "    #z = nn.DataParallel(z, device_ids=selected_gpus, output_device=device)\n",
    "\n",
    "# Setup Adam optimizers for both G and D\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999)) # should be sgd\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100, 1, 1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "   ConvTranspose2d-1            [-1, 128, 2, 2]          51,200\n",
      "         LeakyReLU-2            [-1, 128, 2, 2]               0\n",
      "   ConvTranspose2d-3             [-1, 64, 4, 4]         131,072\n",
      "         LeakyReLU-4             [-1, 64, 4, 4]               0\n",
      "   ConvTranspose2d-5             [-1, 32, 8, 8]          32,768\n",
      "         LeakyReLU-6             [-1, 32, 8, 8]               0\n",
      "   ConvTranspose2d-7           [-1, 32, 16, 16]          16,384\n",
      "         LeakyReLU-8           [-1, 32, 16, 16]               0\n",
      "   ConvTranspose2d-9            [-1, 1, 32, 32]             512\n",
      "             Tanh-10            [-1, 1, 32, 32]               0\n",
      "================================================================\n",
      "Total params: 231,936\n",
      "Trainable params: 231,936\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.20\n",
      "Params size (MB): 0.88\n",
      "Estimated Total Size (MB): 1.08\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(G, input_size=(100, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 16, 16]             512\n",
      "         LeakyReLU-2           [-1, 32, 16, 16]               0\n",
      "            Conv2d-3             [-1, 64, 8, 8]          32,768\n",
      "         LeakyReLU-4             [-1, 64, 8, 8]               0\n",
      "            Conv2d-5            [-1, 128, 4, 4]         131,072\n",
      "         LeakyReLU-6            [-1, 128, 4, 4]               0\n",
      "            Conv2d-7            [-1, 256, 2, 2]         524,288\n",
      "         LeakyReLU-8            [-1, 256, 2, 2]               0\n",
      "            Conv2d-9              [-1, 1, 1, 1]           1,024\n",
      "          Sigmoid-10              [-1, 1, 1, 1]               0\n",
      "================================================================\n",
      "Total params: 689,664\n",
      "Trainable params: 689,664\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.23\n",
      "Params size (MB): 2.63\n",
      "Estimated Total Size (MB): 2.87\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(D, input_size=(1, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
