{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  999\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "#%matplotlib inline\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "from keijzer_exogan import *\n",
    "\n",
    "# Set random seem for reproducibility\n",
    "manualSeed = 999\n",
    "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "\n",
    "#%matplotlib inline\n",
    "%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"} # Make sure the axis background of plots is white, this is usefull for the black theme in JupyterLab\n",
    "#sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0,1,2,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size:  1\n"
     ]
    }
   ],
   "source": [
    "# Root directory for dataset\n",
    "dataroot = \"/datc/opschaler/brian/celeba_complete\"\n",
    "\n",
    "# Number of workers for dataloader\n",
    "workers = 0 # 0 when to_vram is enabled\n",
    "\n",
    "# Batch size during training\n",
    "batch_size = 1 # 2**11\n",
    "print('Batch size: ', batch_size)\n",
    "\n",
    "# Spatial size of training images. All images will be resized to this\n",
    "#   size using a transformer.\n",
    "image_size = 32\n",
    "\n",
    "# Number of channels in the training images. For color images this is 3\n",
    "nc = 1\n",
    "\n",
    "# Size of z latent vector (i.e. size of generator input)\n",
    "nz = 100\n",
    "\n",
    "# Size of feature maps in generator\n",
    "ngf = 32\n",
    "\n",
    "# Size of feature maps in discriminator\n",
    "ndf = 32\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 1 \n",
    "\n",
    "# Learning rate for optimizers\n",
    "lr = 1e-5\n",
    "lr_G = 2e-4\n",
    "\n",
    "# Beta1 hyperparam for Adam optimizers\n",
    "beta1 = 0.5\n",
    "\n",
    "# Number of GPUs available. Use 0 for CPU mode.\n",
    "selected_gpus = [0]\n",
    "ngpu = len(selected_gpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mark the below cell as code to use the celeba dataset"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# We can use an image folder dataset the way we have it setup.\n",
    "# Create the dataset\n",
    "dataset = dset.ImageFolder(root=dataroot,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Grayscale(1),\n",
    "                               transforms.Resize(image_size),\n",
    "                               transforms.CenterCrop(image_size),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create the dataloader\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=workers, pin_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mark the below cell as code to use the ExoGAN dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/16011015/notebooks/SRON-DCGAN/notebooks'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images:  1\n"
     ]
    }
   ],
   "source": [
    "##### Creating custom Dataset classes\n",
    "path = '/datb/16011015/ExoGAN_data/selection//' #notice how you dont put the last folder in here...\n",
    "images = np.load(path+'first_chunks_25_percent_images.npy')\n",
    "\n",
    "shuffle = True\n",
    "\n",
    "if shuffle:\n",
    "    np.random.shuffle(images) # shuffles the images\n",
    "\n",
    "images = images[:1] # select the first image, lateron this has to change to is load a 'selected' image to inpaint (instead of working from this excisting dataset)\n",
    "print('Number of images: ', len(images))\n",
    "\n",
    "dataset = numpy_dataset(data=images, to_vram=True) # to_vram pins it to all GPU's\n",
    "#dataset = numpy_dataset(data=images, to_vram=True, transform=transforms.Compose([transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])) # to_vram pins it to all GPU's\n",
    "\n",
    "# Create the dataloader\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=workers, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9200269a90>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Decide which device we want to run on\n",
    "# Seems to be the main devive, e.g. cuda:0 wont work when only gpu [2,3] are selected... is [2,3] then do cuda:2\n",
    "device = torch.device(\"cuda:\"+str(selected_gpus[0]) if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "\n",
    "# Plot some training images\n",
    "real_batch = next(iter(dataloader))\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator Code\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "\n",
    "        \"\"\"\n",
    "        where (in_channels, out_channels, \n",
    "        kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1)\n",
    "        \"\"\"\n",
    "        self.main = nn.Sequential(\n",
    "            \n",
    "            #1\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            #4\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout2d(0.5),\n",
    "            \n",
    "            #7\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout2d(0.5),\n",
    "            \n",
    "            #10\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d( ngf * 2, ngf*1, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf*1),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            # Go from 1x64x64 to 1x32x32\n",
    "            nn.Conv2d(ngf, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf*1),\n",
    "            nn.ReLU(True),\n",
    "                        #10\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            #nn.ConvTranspose2d( ngf * 2, ngf*1, 4, 2, 1, bias=False),\n",
    "            #nn.BatchNorm2d(ngf*1),\n",
    "            #nn.ReLU(True),\n",
    "            \n",
    "            #13\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d(ngf*1, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (main): Sequential(\n",
      "    (0): ConvTranspose2d(100, 256, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace)\n",
      "    (6): Dropout2d(p=0.5)\n",
      "    (7): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace)\n",
      "    (10): Dropout2d(p=0.5)\n",
      "    (11): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (12): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (13): ReLU(inplace)\n",
      "    (14): Conv2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (15): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace)\n",
      "    (17): ConvTranspose2d(32, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (18): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create the generator\n",
    "netG = Generator(ngpu).to(device)\n",
    "\n",
    "# Handle multi-gpu if desired\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    netG = nn.DataParallel(netG, device_ids=selected_gpus, output_device=device) # select only gpu 0, 2, 3\n",
    "\n",
    "# Apply the weights_init function to randomly initialize all weights\n",
    "#  to mean=0, stdev=0.2.\n",
    "netG.apply(weights_init)\n",
    "\n",
    "# Print the model\n",
    "print(netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (main): Sequential(\n",
      "    (0): ConvTranspose2d(100, 256, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace)\n",
      "    (6): Dropout2d(p=0.5)\n",
      "    (7): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace)\n",
      "    (10): Dropout2d(p=0.5)\n",
      "    (11): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (12): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (13): ReLU(inplace)\n",
      "    (14): Conv2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (15): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace)\n",
      "    (17): ConvTranspose2d(32, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (18): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Apply the weights_init function to randomly initialize all weights\n",
    "#  to mean=0, stdev=0.2.\n",
    "netG.apply(weights_init)\n",
    "\n",
    "# Print the model\n",
    "print(netG)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
    "noise.shape\n",
    "summary(netG, (100,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 1, 4, 2, 1, bias=False),\n",
    "            #nn.BatchNorm2d(ndf * 1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 1, ndf * 2, 4, 2, 1, bias=False),\n",
    "            #nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            #nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            #nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            nn.Conv2d(ndf * 8, 1, 1, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (main): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (2): Conv2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (3): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (4): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (5): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (6): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (8): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (9): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (10): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (11): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create the Discriminator\n",
    "netD = Discriminator(ngpu).to(device)\n",
    "\n",
    "# Handle multi-gpu if desired\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    print('netD to cuda')\n",
    "    netD = nn.DataParallel(netD, device_ids=selected_gpus, output_device=device) # select only gpu 0, 2, 3\n",
    "\n",
    "# Apply the weights_init function to randomly initialize all weights\n",
    "#  to mean=0, stdev=0.2.\n",
    "netD.apply(weights_init)\n",
    "\n",
    "# Print the model\n",
    "print(netD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 16, 16]             512\n",
      "         LeakyReLU-2           [-1, 32, 16, 16]               0\n",
      "            Conv2d-3             [-1, 32, 8, 8]          16,384\n",
      "         LeakyReLU-4             [-1, 32, 8, 8]               0\n",
      "            Conv2d-5             [-1, 64, 4, 4]          32,768\n",
      "         LeakyReLU-6             [-1, 64, 4, 4]               0\n",
      "            Conv2d-7            [-1, 128, 2, 2]         131,072\n",
      "         LeakyReLU-8            [-1, 128, 2, 2]               0\n",
      "            Conv2d-9            [-1, 256, 1, 1]         524,288\n",
      "        LeakyReLU-10            [-1, 256, 1, 1]               0\n",
      "           Conv2d-11              [-1, 1, 1, 1]             256\n",
      "          Sigmoid-12              [-1, 1, 1, 1]               0\n",
      "================================================================\n",
      "Total params: 705,280\n",
      "Trainable params: 705,280\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.18\n",
      "Params size (MB): 2.69\n",
      "Estimated Total Size (MB): 2.88\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(netD, (1,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BCELoss function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Create batch of latent vectors that we will use to visualize\n",
    "#  the progression of the generator\n",
    "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "\n",
    "# Establish convention for real and fake labels during training\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "# Setup Adam optimizers for both G and D\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999)) # should be sgd\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr_G, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time as t\n",
    "\n",
    "# Training Loop\n",
    "\n",
    "# Lists to keep track of progress\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_D = True\n",
    "train_G = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved weights\n",
    "netG.load_state_dict(torch.load('netG_state_dict', map_location=device)) #net.module..load_... for parallel model , net.load_... for single gpu model\n",
    "netD.load_state_dict(torch.load('netD_state_dict', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "   ConvTranspose2d-1            [-1, 256, 4, 4]         409,600\n",
      "       BatchNorm2d-2            [-1, 256, 4, 4]             512\n",
      "              ReLU-3            [-1, 256, 4, 4]               0\n",
      "   ConvTranspose2d-4            [-1, 128, 8, 8]         524,288\n",
      "       BatchNorm2d-5            [-1, 128, 8, 8]             256\n",
      "              ReLU-6            [-1, 128, 8, 8]               0\n",
      "         Dropout2d-7            [-1, 128, 8, 8]               0\n",
      "   ConvTranspose2d-8           [-1, 64, 16, 16]         131,072\n",
      "       BatchNorm2d-9           [-1, 64, 16, 16]             128\n",
      "             ReLU-10           [-1, 64, 16, 16]               0\n",
      "        Dropout2d-11           [-1, 64, 16, 16]               0\n",
      "  ConvTranspose2d-12           [-1, 32, 32, 32]          32,768\n",
      "      BatchNorm2d-13           [-1, 32, 32, 32]              64\n",
      "             ReLU-14           [-1, 32, 32, 32]               0\n",
      "           Conv2d-15           [-1, 32, 16, 16]          16,384\n",
      "      BatchNorm2d-16           [-1, 32, 16, 16]              64\n",
      "             ReLU-17           [-1, 32, 16, 16]               0\n",
      "  ConvTranspose2d-18            [-1, 1, 32, 32]             512\n",
      "             Tanh-19            [-1, 1, 32, 32]               0\n",
      "================================================================\n",
      "Total params: 1,115,648\n",
      "Trainable params: 1,115,648\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.80\n",
      "Params size (MB): 4.26\n",
      "Estimated Total Size (MB): 6.05\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(netG, (100,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of Discriminator(\n",
       "  (main): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    (2): Conv2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (3): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    (4): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (5): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    (6): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (7): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    (8): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (9): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    (10): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (11): Sigmoid()\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netD.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 16, 16]             512\n",
      "         LeakyReLU-2           [-1, 32, 16, 16]               0\n",
      "            Conv2d-3             [-1, 32, 8, 8]          16,384\n",
      "         LeakyReLU-4             [-1, 32, 8, 8]               0\n",
      "            Conv2d-5             [-1, 64, 4, 4]          32,768\n",
      "         LeakyReLU-6             [-1, 64, 4, 4]               0\n",
      "            Conv2d-7            [-1, 128, 2, 2]         131,072\n",
      "         LeakyReLU-8            [-1, 128, 2, 2]               0\n",
      "            Conv2d-9            [-1, 256, 1, 1]         524,288\n",
      "        LeakyReLU-10            [-1, 256, 1, 1]               0\n",
      "           Conv2d-11              [-1, 1, 1, 1]             256\n",
      "          Sigmoid-12              [-1, 1, 1, 1]               0\n",
      "================================================================\n",
      "Total params: 705,280\n",
      "Trainable params: 705,280\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.18\n",
      "Params size (MB): 2.69\n",
      "Estimated Total Size (MB): 2.88\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(netD, (1,32,32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inpainting\n",
    "TODO: Implement the following\n",
    "\n",
    "The corrupted image $y$ is mapped to the closest $z$ in the latent representation space, this mapping is denoted as $\\hat{z}$.\n",
    "    \n",
    "$\\hat{z} = \\operatorname{arg\\,min}_z \\{ \\mathcal{L}_c(z |y, M) + \\mathcal{L}_p (z) \\}$\n",
    "\n",
    "where\n",
    "\n",
    "$\\mathcal{L}_c(z |y, M) = || M \\bigodot G(z) - M \\bigodot y||_1 = || M \\bigodot (G(z)-y) ||_1 $\n",
    "\n",
    "with $c$ being contextual loss and $M$ being a binary mask with the same size as $y$,\n",
    "\n",
    "$\\mathcal{L}_p (z) = \\lambda \\operatorname{log}(1-D(G(z)))$\n",
    "\n",
    "with $p$ being perceptual loss and $D$ being the discriminator.\n",
    "\n",
    "Once $G(\\hat{z})$ is generated, the final solution $\\hat{x}$ is calculated as\n",
    "\n",
    "$\\hat{x} = \\operatorname{arg\\, min}_x ||\\nabla x - \\nabla G(\\hat{z}) ||^2_2$  \n",
    "\n",
    "(substitute $x_i = y_i$ for $M_i = 1$).\n",
    "\n",
    "-----\n",
    "\n",
    "$|| ... ||$ is done by `torch.norm()`.  \n",
    "$... \\bigodot ...$ is done by `torch.mul()`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100, 1, 1])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (re)define variables (for clarity)\n",
    "\n",
    "G = netG\n",
    "D = netD\n",
    "z = torch.randn(1, nz, 1, 1, requires_grad=True, device=device)\n",
    "\n",
    "lamb = 3e-3\n",
    "\n",
    "criteria = nn.BCELoss()\n",
    "\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters = 1*10**3 # number of iters to do for inpainting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images = []\n",
    "masked_images= []\n",
    "inpainted_images = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.shape:  torch.Size([1, 1, 32, 32])\n",
      "image.shape:  torch.Size([1, 1, 32, 32])\n",
      "mask.shape torch.Size([1, 1, 32, 32])\n",
      "masked image shape torch.Size([1, 1, 32, 32])\n",
      " iteration :  999 , context_loss: 235.1906, perceptual_loss: -0.875369, total_loss: 235.187958"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, data in enumerate(dataloader, 0): # batches per epoch\n",
    "    real_cpu = data.to(device)\n",
    "    b_size = real_cpu.size(0) # this is one ofc, it's one image we're trying to inpaint\n",
    "\n",
    "    print(\"data.shape: \", data.shape)\n",
    "    image = data.to(device) # select the image (Channel, Height, Width), this is the original unmasked input image\n",
    "    real_images.append(image)\n",
    "    print(\"image.shape: \", image.shape)\n",
    "\n",
    "    \"\"\"Mask the images manually, for testing pruposes\"\"\"\n",
    "    mask = torch.ones(size=image.shape).to(device) # create mask with 1's in the shape of image\n",
    "    \n",
    "    print(\"mask.shape\", mask.shape)\n",
    "\n",
    "    # use a random 'easy' mask\n",
    "    mask[:, :, 10:20, 5:15] = 0\n",
    "\n",
    "    masked_image = torch.mul(image, mask).to(device) #image bigodot mask\n",
    "    masked_images.append(masked_image)\n",
    "    print('masked image shape', masked_image.shape)\n",
    "    plt.imshow(masked_image.detach().cpu()[0, 0, :, :], cmap='gray') # plot the masked image\n",
    "\n",
    "    opt = optim.Adam([z], lr=lr)\n",
    "\n",
    "    # what's v and m?\n",
    "    v = torch.tensor(0, dtype=torch.float32, device=device)\n",
    "    m = torch.tensor(0, dtype=torch.float32, device=device)\n",
    "\n",
    "\n",
    "    \"\"\"Start the inpainting process\"\"\"\n",
    "    for iteration in range(n_iters):\n",
    "        if z.grad is not None:\n",
    "            z.grad.data.zero_()\n",
    "\n",
    "        G.zero_grad()\n",
    "        D.zero_grad()\n",
    "\n",
    "\n",
    "        image_generated = G(z) # generated image G(z)\n",
    "        image_generated_masked = torch.mul(image_generated, mask) # G(z) bigodot M\n",
    "        image_generated_inpainted = torch.mul(image_generated, (1-mask))+masked_image\n",
    "        \n",
    "        if (iteration % 10 == 0):\n",
    "            inpainted_images.append(image_generated_inpainted)\n",
    "\n",
    "        #print(\"image_generated_inpainted.shape : \",image_generated_inpainted.shape)\n",
    "\n",
    "        t = image_generated_inpainted.detach().cpu()[0, 0, :, :]\n",
    "\n",
    "        # TODO: why does this already look real?\n",
    "        plt.imshow(t, cmap='gray') # plot the masked image \n",
    "\n",
    "        \"\"\"Calculate losses\"\"\"\n",
    "        loss_context = torch.norm(image_generated_masked-masked_image, p=1) #what's p=1?\n",
    "        discriminator_output = netD(image_generated_inpainted)\n",
    "        #print(\"Discriminator output: \", discriminator_output)\n",
    "\n",
    "        labels = torch.full((b_size,), 1, device=device)\n",
    "        loss_perceptual = torch.log(1-discriminator_output)\n",
    "        \n",
    "        #print(loss_perceptual.data.cpu().numpy().flatten()[0])\n",
    "\n",
    "        total_loss = loss_context + lamb*loss_perceptual\n",
    "        \n",
    "        # grab the values from losses for printing\n",
    "        loss_perceptual = loss_perceptual.data.cpu().numpy().flatten()[0]\n",
    "        loss_context = loss_context.data.cpu().numpy().flatten()[0]\n",
    "\n",
    "\n",
    "\n",
    "        total_loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        total_loss = total_loss.data.cpu().numpy().flatten()[0]\n",
    "        \n",
    "        print(\"\\r iteration : {:4} , context_loss: {:.4f}, perceptual_loss: {:4f}, total_loss: {:4f}\".format(iteration,loss_context,loss_perceptual, total_loss),end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1584x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "real = real_images[0].detach().cpu()[0, 0, :, :]\n",
    "real_masked = masked_images[0].detach().cpu()[0, 0, :, :]\n",
    "\n",
    "first_generated =inpainted_images[1].detach().cpu()[0, 0, :, :]\n",
    "last_generated = inpainted_images[-1].detach().cpu()[0, 0, :, :]\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(22,10))\n",
    "\n",
    "plt.subplot(1,4,1)\n",
    "plt.imshow(real, cmap='gray')\n",
    "\n",
    "plt.subplot(1,4,2)\n",
    "plt.imshow(real_masked, cmap='gray')\n",
    "\n",
    "plt.subplot(1,4,3)\n",
    "plt.imshow(first_generated, cmap='gray')\n",
    "\n",
    "plt.subplot(1,4,4)\n",
    "plt.imshow(last_generated, cmap='gray')\n",
    "\n",
    "plt.imshow\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams['animation.embed_limit'] = 20**128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "ims = [[plt.imshow(i.detach().cpu()[0, 0, :, :], animated=True, cmap='gray')] for i in inpainted_images]\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=500, repeat_delay=1000, blit=True)\n",
    "\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
