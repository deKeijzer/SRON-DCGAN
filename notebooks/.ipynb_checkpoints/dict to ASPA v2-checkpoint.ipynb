{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook functionizes the 'Array to ASPA'. Goal is to convert any input dictionary to a usable ASPA for analysis.\n",
    "\n",
    "IMPORTANT:\n",
    "During the visualisation of the images. Each cmap per individual image is scaled depending on the contents. Therefor the images array has to be saved and used... Saving the PNG's will give faulty results. \n",
    "\n",
    "TODO:\n",
    "Split up all features into e.g. 4 scales so they can be scaled and distuingished better?\n",
    "But also reserve space for 'cloud' models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keijzer_exogan import *\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"} # Make sure the axis background of plots is white, this is usefull for the black theme in JupyterLab\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load chunk\n",
    "X[0] is a dict from regular chunk  \n",
    "X[0][0] is a dict from .npy selection  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_ = '/datb/16011015/ExoGAN_data//'\n",
    "\n",
    "X = np.load(dir_+'selection/last_chunks_25_percent.npy')\n",
    "X = X.flatten()\n",
    "\n",
    "np.random.seed(23) # Set seed for the np.random functions\n",
    "\n",
    "# Shuffle X along the first axis to make the order of simulations random\n",
    "np.random.shuffle(X) # note that X = np.rand.... isn't required\n",
    "\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data\n",
    "def scale_param(X, X_min, X_max):\n",
    "    \"\"\"\n",
    "    Formule source: \n",
    "    https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html\n",
    "    \n",
    "    In this case 1 is max, 0 is min\n",
    "    \"\"\"\n",
    "    std = (X-X_min)/ (X_max - X_min)\n",
    "    return std*(1 - 0)+0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = 'gray'\n",
    "\n",
    "\"\"\"\n",
    "Transforms the input dictionary (in the format of ExoGAN), to the ASPA format.\n",
    "TODO:\n",
    "\n",
    "- devide each parameter in bins and scale the data per bin (to hopefully increase the contrast in the data)\n",
    "- make sure to leave space for cloud model information (max2, min2 is currently double info from max1, min1)\n",
    "\"\"\"\n",
    "\n",
    "spectrum = x['data']['spectrum']\n",
    "\n",
    "if len(spectrum) != 515:\n",
    "    print('Spectrum length != 515. breaking script')\n",
    "    #break\n",
    "\n",
    "\"\"\"\n",
    "Scale the spectrum\n",
    "\"\"\"\n",
    "spectrum = spectrum.reshape(-1, 1) # convert 1D array to 2D cause standardscaler requires it\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1)).fit(spectrum)\n",
    "std = np.std(spectrum)\n",
    "min_ = spectrum.min()\n",
    "max_ = spectrum.max()\n",
    "\n",
    "spectrum = scaler.transform(spectrum)\n",
    "\n",
    "# fill spectrum to have a size of 529, to then reshape to 23x23\n",
    "spectrum = np.append(spectrum, [0 for _ in range(14)]) # fill array to size 529 with zeroes\n",
    "spectrum = spectrum.reshape(23, 23) # building block one\n",
    "\n",
    "# Also scale min_ max_ from the spectrum\n",
    "min_ = scale_param(min_, 6.5e-3, 2.6e-2)\n",
    "max_ = scale_param(max_, 6.5e-3, 2.6e-2)\n",
    "\n",
    "\"\"\"\n",
    "Add the different building blocks to each other\n",
    "\"\"\"\n",
    "\n",
    "max1 = np.full((12,6), max_) # create array of shape 12,6 (height, width) with the max_ value\n",
    "min1 = np.full((11,6), min_)\n",
    "max1min1 = np.concatenate((max1, min1), axis=0) # Add min1 below max1 (axis=0) \n",
    "\n",
    "image = np.concatenate((spectrum, max1min1), axis=1) # Add max1min1 to the right of spectrum (axis=1)\n",
    "\n",
    "\"\"\"\n",
    "Get all parameters and scale them\n",
    "\"\"\"\n",
    "# Get the param values\n",
    "ch4 = x['param']['ch4_mixratio']\n",
    "co2 = x['param']['co2_mixratio']\n",
    "co = x['param']['co_mixratio']\n",
    "h2o = x['param']['h2o_mixratio']\n",
    "mass = x['param']['planet_mass']\n",
    "radius = x['param']['planet_radius']\n",
    "temp = x['param']['temperature_profile']\n",
    "\n",
    "# Scale params (parm, min_value, max_value) where min/max should be the \n",
    "ch4 = scale_param(ch4, 1e-8, 1e-1)\n",
    "co2 = scale_param(co2, 1e-8, 1e-1)\n",
    "co = scale_param(co, 1e-8, 1e-1)\n",
    "h2o = scale_param(h2o, 1e-8, 1e-1)\n",
    "mass = scale_param(mass, 1.5e27, 3.8e27)\n",
    "radius = scale_param(radius, 5.6e7, 1.0e8)\n",
    "temp = scale_param(temp, 1e3, 2e3)\n",
    "\n",
    "# Create the building blocks\n",
    "co2 = np.full((23,1), co2)\n",
    "co = np.full((23,1), co)\n",
    "ch4 = np.full((23,1), ch4)\n",
    "\n",
    "\n",
    "mass = np.full((1,23), mass)\n",
    "radius = np.full((1,23), radius)\n",
    "temp = np.full((1,23), temp)\n",
    "\n",
    "h2o = np.full((9,9), h2o)\n",
    "\n",
    "max2 = np.full((6,12), max_) # create array of shape 12,7 (height, width) with the max_ value\n",
    "min2 = np.full((6,11), min_)\n",
    "\n",
    "\"\"\"\n",
    "Put building blocks together\n",
    "\"\"\"\n",
    "image = np.concatenate((image, co2), axis=1)\n",
    "image = np.concatenate((image, co), axis=1)\n",
    "image = np.concatenate((image, ch4), axis=1)\n",
    "\n",
    "sub_image = np.concatenate((max2, min2), axis=1)\n",
    "sub_image = np.concatenate((sub_image, mass), axis=0)\n",
    "sub_image = np.concatenate((sub_image, radius), axis=0)\n",
    "sub_image = np.concatenate((sub_image, temp), axis=0)\n",
    "sub_image = np.concatenate((sub_image, h2o), axis=1)\n",
    "\n",
    "image = np.concatenate((image, sub_image), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New ASPA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data, combine $(R_p/R_s)^2$ with the wavelength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.random.randint(0,len(X))\n",
    "x = X[i] # select a dict from X\n",
    "\n",
    "\n",
    "wavelengths = pd.read_csv(dir_+'wnw_grid.txt', header=None).values\n",
    "spectrum = x['data']['spectrum']\n",
    "spectrum = np.expand_dims(spectrum, axis=1) # change shape from (515,) to (515,1)\n",
    "params = x['param']\n",
    "\n",
    "for param in params:\n",
    "    if 'mixratio' in param: \n",
    "        params[param] = np.log(np.abs(params[param])) # transform mixratio's because they are generated on logarithmic scale\n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min max values from training set, in the same order as params above: planet mass, temp, .... co mixratio.\n",
    "min_values = [1.518e26, 1e3, -18.42, 5.593e7, -18.42, -18.42, -18.42]\n",
    "max_values = [3.796e27, 2e3, -2.303, 1.049e8, -2.306, -2.306, -2.306]\n",
    "\n",
    "for i,param in enumerate(params):\n",
    "    params[param] = scale_param(params[param], min_values[i], max_values[i])\n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelengths.shape, spectrum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.concatenate([wavelengths,spectrum], axis=1)\n",
    "data = pd.DataFrame(data)\n",
    "data.columns = ['x', 'y'] # x is wavelength, y is (R_p / R_s)^2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original ExoGAN simulation\n",
    "From 0.3 to 50 micron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.plot(data.x, data.y, '.-', color='r')\n",
    "plt.xlabel(r'Wavelength [µm]')\n",
    "plt.ylabel(r'$(R_P / R_S)^2$')\n",
    "\n",
    "plt.xscale('log')\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select 0.3 to 16 micron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[(data.x >= 0.3) & (data.x <= 16)] # select data between 0.3 and 16 micron\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.plot(data.x, data.y, '.-', color='r')\n",
    "plt.xlabel(r'Wavelength [µm]')\n",
    "plt.ylabel(r'$(R_P / R_S)^2$')\n",
    "\n",
    "#plt.xscale('log')\n",
    "plt.xlim((2, 16))\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important!\n",
    "Notice how $(R_p/R_s)^2$ by index goes from a high to a low wavelength.  \n",
    "Apart from that, i'm assuming the spatial difference between peaks is due to plotting against the index instead of the wavelength.  \n",
    "The spectrum (below) will remain unchanged and is encoded this way into an ASPA, the wavelength values from above therefor have to be used to transform the ASPA back into $(R_p/R_s)^2$ with the wavelength values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spectrum = np.flipud(data.y)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.plot(data.y, '.-', color='r')\n",
    "plt.xlabel(r'Index')\n",
    "plt.ylabel(r'$(R_P / R_S)^2$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the spectrum in bins "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Could loop this, but right now this is more visual\n",
    "bin1 = data[data.x <= 0.8]\n",
    "bin2 = data[(data.x > 0.8) & (data.x <= 1.3)] # select data between 2 and 4 micron\n",
    "bin3 = data[(data.x > 1.3) & (data.x <= 2)]\n",
    "bin4 = data[(data.x > 2) & (data.x <= 4)]\n",
    "bin5 = data[(data.x > 4) & (data.x <= 6)]\n",
    "bin6 = data[(data.x > 6) & (data.x <= 10)]\n",
    "bin7 = data[(data.x > 10) & (data.x <= 14)]\n",
    "bin8 = data[data.x > 14]\n",
    "\n",
    "bin1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bins against wavelength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Visualize the bins\n",
    "\"\"\"\n",
    "\n",
    "bins = [bin8, bin7, bin6, bin5, bin4, bin3, bin2, bin1]\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "for b in bins:\n",
    "    plt.plot(b.iloc[:,0], b.iloc[:,1], '.-')\n",
    "    plt.xlabel(r'Wavelength [µm]')\n",
    "    plt.ylabel(r'$(R_P / R_S)^2$')\n",
    "    \n",
    "#plt.xlim((0.3, 9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bins against index\n",
    "Notice how bin1 (0-2 micron) has way more datapoints than bin 8 (14-16 micron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "for b in bins:\n",
    "    plt.plot(b.iloc[:,1], '.-')\n",
    "    plt.xlabel(r'Index [-]')\n",
    "    plt.ylabel(r'$(R_P / R_S)^2$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize the spectrum in bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = [MinMaxScaler(feature_range=(0,1)).fit(b) for b in bins] # list of 8 scalers for the 8 bins\n",
    "mins = [ b.iloc[:,1].min() for b in bins] # .iloc[:,1] selects the R/R (y) only\n",
    "maxs = [ b.iloc[:,1].max() for b in bins]\n",
    "stds = [ b.iloc[:,1].std() for b in bins]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_scaled = []\n",
    "for i,b in enumerate(bins):\n",
    "    bins_scaled.append(scalers[i].transform(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "for i,b in enumerate(bins_scaled):\n",
    "    plt.plot(b[:, 0], b[:,1], '.-', label=i)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate(bins_scaled, axis=0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaled spectrum in bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum_scaled = np.concatenate(bins_scaled, axis=0)\n",
    "spectrum_scaled = spectrum_scaled[:,1]\n",
    "\n",
    "plt.plot(spectrum_scaled, '.-')\n",
    "\n",
    "len(spectrum_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start creating the ASPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspa = np.zeros((32,32))\n",
    "\n",
    "row_length = 25 # amount of pixels used per row\n",
    "n_rows = math.ceil(len(spectrum_scaled) / row_length) # amount of rows the spectrum needs in the aspa, so for 415 data points, 415/32=12.96 -> 13 rows\n",
    "print('Using %s rows' % n_rows)\n",
    "\n",
    "for i in range(n_rows): # for i in \n",
    "\n",
    "    start = i*row_length\n",
    "    stop = start+row_length\n",
    "    spec = spectrum_scaled[start:stop]\n",
    "    \n",
    "    if len(spec) != row_length:\n",
    "        n_missing_points = row_length-len(spec)\n",
    "        spec = np.append(spec, [0 for _ in range(n_missing_points)]) # for last row, if length != 32, fill remaining with 0's\n",
    "        print('Filled row with %s points' % n_missing_points)\n",
    "        \n",
    "    aspa[i, :row_length] = spec\n",
    "\n",
    "plt.imshow(aspa, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill in the 7 ExoGAN params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,param in enumerate(params):\n",
    "    aspa[:16, 25+i:32+i] = params[param]\n",
    "\n",
    "plt.imshow(aspa, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill in the min, max, std valued for the bins\n",
    "TODO: Normalize these properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mins, maxs, stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(mins)):\n",
    "    min_ = scale_param(mins[i], 0.005, 0.03)\n",
    "    max_ = scale_param(maxs[i], 0.005, 0.03)\n",
    "    std_ = scale_param(stds[i], 1e-7, 1e-4)\n",
    "    \n",
    "    aspa[16:17, i*4:i*4+4] = min_\n",
    "    aspa[17:18, i*4:i*4+4] = std_\n",
    "    aspa[18:19, i*4:i*4+4] = max_\n",
    "    \n",
    "    \n",
    "    print(min_, max_, std_)\n",
    "\n",
    "plt.imshow(aspa, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill in unused space with noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(13):\n",
    "    noise = np.random.rand(32) # random noise betweem 0 and 1 for each row\n",
    "    aspa[19+i:20+i*1, :] = noise\n",
    "\n",
    "plt.imshow(aspa, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functionize ASPA v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ASPA_v2(x, wavelengths):\n",
    "    spectrum = x['data']['spectrum']\n",
    "    spectrum = np.expand_dims(spectrum, axis=1) # change shape from (515,) to (515,1)\n",
    "    params = x['param']\n",
    "\n",
    "    for param in params:\n",
    "        if 'mixratio' in param: \n",
    "            params[param] = np.log(np.abs(params[param])) # transform mixratio's because they are generated on logarithmic scale\n",
    "    \n",
    "    \"\"\"\n",
    "    Normalize params\n",
    "    \"\"\"\n",
    "    # Min max values from training set, in the same order as params above: planet mass, temp, .... co mixratio.\n",
    "    min_values = [1.518400e+27, \n",
    "                  1.000000e+03, \n",
    "                  -1.842068e+01, \n",
    "                  5.592880e+07, \n",
    "                  -1.842068e+01, \n",
    "                  -1.842068e+01, \n",
    "                  -1.842068e+01]\n",
    "    \n",
    "    max_values = [3.796000e+27, \n",
    "                  2.000000e+03, \n",
    "                  -2.302585e+00, \n",
    "                  1.048665e+08, \n",
    "                  -2.302585e+00, \n",
    "                  -2.302585e+00,\n",
    "                  -2.302585e+00]\n",
    "\n",
    "    for i,param in enumerate(params):\n",
    "        params[param] = scale_param(params[param], min_values[i], max_values[i])\n",
    "        #print('%s: %s' % (param, params[param]))\n",
    "    #print('-'*5)\n",
    "    \"\"\"\n",
    "    Select bins\n",
    "    \"\"\"\n",
    "    data = np.concatenate([wavelengths,spectrum], axis=1)\n",
    "    data = pd.DataFrame(data)\n",
    "    data.columns = ['x', 'y'] # x is wavelength, y is (R_p / R_s)^2\n",
    "    \n",
    "    # Could loop this, but right now this is more visual\n",
    "    bin1 = data[data.x <= 0.8]\n",
    "    bin2 = data[(data.x > 0.8) & (data.x <= 1.3)] # select data between 2 and 4 micron\n",
    "    bin3 = data[(data.x > 1.3) & (data.x <= 2)]\n",
    "    bin4 = data[(data.x > 2) & (data.x <= 4)]\n",
    "    bin5 = data[(data.x > 4) & (data.x <= 6)]\n",
    "    bin6 = data[(data.x > 6) & (data.x <= 10)]\n",
    "    bin7 = data[(data.x > 10) & (data.x <= 14)]\n",
    "    bin8 = data[data.x > 14]\n",
    "\n",
    "    bins = [bin8, bin7, bin6, bin5, bin4, bin3, bin2, bin1]\n",
    "    \n",
    "    \"\"\"\n",
    "    Normalize bins\n",
    "    \"\"\"\n",
    "    scalers = [MinMaxScaler(feature_range=(0,1)).fit(b) for b in bins] # list of 8 scalers for the 8 bins\n",
    "    mins = [ b.iloc[:,1].min() for b in bins] # .iloc[:,1] selects the R/R (y) only\n",
    "    maxs = [ b.iloc[:,1].max() for b in bins]\n",
    "    stds = [ b.iloc[:,1].std() for b in bins]\n",
    "    #print(min(mins), max(maxs))\n",
    "    bins_scaled = []\n",
    "    for i,b in enumerate(bins):\n",
    "        bins_scaled.append(scalers[i].transform(b))\n",
    "        \n",
    "    spectrum_scaled = np.concatenate(bins_scaled, axis=0)\n",
    "    spectrum_scaled = spectrum_scaled[:,1]\n",
    "    \n",
    "    \"\"\"\n",
    "    Create the ASPA\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"Spectrum\"\"\"\n",
    "    aspa = np.zeros((32,32))\n",
    "\n",
    "    row_length = 25 # amount of pixels used per row\n",
    "    n_rows = math.ceil(len(spectrum_scaled) / row_length) # amount of rows the spectrum needs in the aspa, so for 415 data points, 415/32=12.96 -> 13 rows\n",
    "    #print('Using %s rows' % n_rows)\n",
    "\n",
    "    for i in range(n_rows): # for i in \n",
    "\n",
    "        start = i*row_length\n",
    "        stop = start+row_length\n",
    "        spec = spectrum_scaled[start:stop]\n",
    "\n",
    "        if len(spec) != row_length:\n",
    "            n_missing_points = row_length-len(spec)\n",
    "            spec = np.append(spec, [0 for _ in range(n_missing_points)]) # for last row, if length != 32, fill remaining with 0's\n",
    "            #print('Filled row with %s points' % n_missing_points)\n",
    "\n",
    "        aspa[i, :row_length] = spec\n",
    "        \n",
    "    \"\"\"ExoGAN params\"\"\"\n",
    "    for i,param in enumerate(params):\n",
    "        aspa[:16, 25+i:26+i] = params[param]\n",
    "        \n",
    "    \"\"\"min max std values for spectrum bins\"\"\"\n",
    "    for i in range(len(mins)):\n",
    "        min_ = scale_param(mins[i], 0.005, 0.03)\n",
    "        max_ = scale_param(maxs[i], 0.005, 0.03)\n",
    "        std_ = scale_param(stds[i], 9e-6, 2e-4)\n",
    "\n",
    "        aspa[16:17, i*4:i*4+4] = min_\n",
    "        aspa[17:18, i*4:i*4+4] = std_\n",
    "        aspa[18:19, i*4:i*4+4] = max_\n",
    "        \n",
    "    \"\"\"Fill unused space with noice\"\"\"\n",
    "    for i in range(13):\n",
    "        noise = np.random.rand(32) # random noise betweem 0 and 1 for each row\n",
    "        aspa[19+i:20+i*1, :] = noise\n",
    "        \n",
    "    return aspa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test ASPA v2 function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.random.randint(0,len(X))\n",
    "dict_ = X[i] # select a dict from X\n",
    "\n",
    "wavelengths = pd.read_csv(dir_+'wnw_grid.txt', header=None).values\n",
    "\n",
    "dict_['param']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspa = ASPA_v2(dict_, wavelengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(aspa, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,20))\n",
    "\n",
    "for i in range(8*4):\n",
    "    image = ASPA_v2(X[i], wavelengths)\n",
    "    \n",
    "\n",
    "    plt.subplot(8, 4, i+1)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating images from all simulations in the chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for i in tqdm(range(len(X))):\n",
    "    image = ASPA_v2(X[i], wavelengths)\n",
    "    image = image.reshape(1, 32, 32) # [images, channel, width, height]\n",
    "    images.append(image)\n",
    "    \n",
    "images = np.array(images)\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving this array to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "np.save(dir_+'selection/last_chunks_25_percent_images.npy', images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test loading and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.load('/datb/16011015/ExoGAN_data/selection/last_chunks_25_percent_images.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[0,0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,20))\n",
    "\n",
    "for i in range(8*4):\n",
    "    plt.subplot(8, 4, i+1)\n",
    "    plt.imshow(images[i,0,:,:], cmap='gnuplot2')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomly mask pixels from the encoded spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = images[0, 0, :, :]\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image[:23, :23] is the encoded spectrum.\n",
    "t = image.copy()\n",
    "print(t.shape)\n",
    "#t[:23, :23] = 0\n",
    "plt.imshow(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random uniform dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = image.copy()\n",
    "dropout = 0.9\n",
    "\n",
    "for i in range(24): # loop over rows\n",
    "    for j in range(24): # loop over cols\n",
    "        a = np.random.random() # random uniform dist 0 - 1\n",
    "        if a < dropout:\n",
    "            t[i-1:i, j-1:j] = 0\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image[:23, :23] is the encoded spectrum.\n",
    "t = image.copy()\n",
    "\n",
    "#t[:23, :23] = 0\n",
    "plt.imshow(t)\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Range dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Mask everything but the visible spectrum\n",
    "\n",
    "def mask_image(image, visible_length, random_visible_spectrum=True):\n",
    "    \"\"\"\n",
    "    Masks everything in an input image, apart from the start to visible_length. \n",
    "    \n",
    "    start = start wavelength/index value of the visible (non masked) spectrum\n",
    "    visible_length = length of the visible spectrum (in pixels)\n",
    "    output: masked_image\n",
    "    \"\"\"\n",
    "\n",
    "    image_masked = image.copy()\n",
    "    \n",
    "    spectrum_length = 23*23 # length of spectrum in ASPA\n",
    "    start_max = spectrum_length - visible_length # maximum value start can have to still be able to show spectrum of length visible_length\n",
    "    start = np.random.randint(0, start_max)\n",
    "\n",
    "    # start stop index to mask before the visible (not masked) spectrum / sequence\n",
    "\n",
    "    stop = start + visible_length # stop index of unmasked sequence\n",
    "\n",
    "    spectrum = image_masked[:23, :23].flatten() # flatten the spectrum\n",
    "    spectrum[:start] = 0\n",
    "    spectrum[stop:] = 0\n",
    "    spectrum = spectrum.reshape(23, 23)\n",
    "\n",
    "    #t[:, :] = 0\n",
    "\n",
    "    image_masked[:23, :23] = spectrum\n",
    "\n",
    "    image_masked[:, 29:] = 0 # right side params\n",
    "    image_masked[29:, :] = 0 # bottom params\n",
    "    image_masked[23:, 23:] = 0 # h2o\n",
    "\n",
    "    image_masked = image_masked.reshape(1, 32, 32) # add the channel dimension back \n",
    "    \n",
    "    return image_masked\n",
    "\n",
    "\n",
    "image = images[0, 0, :, :].copy()\n",
    "visible_length = 46 # length of the visible (not to mask) spectrum\n",
    "\n",
    "image_masked = mask_image(image, visible_length)\n",
    "plt.imshow(image_masked[0, :, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Also mask params and h2o\n",
    "Leaving min max values for now (they will get updated anyway)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
