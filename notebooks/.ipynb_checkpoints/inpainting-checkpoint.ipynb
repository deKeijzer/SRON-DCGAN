{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import random\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as vutils\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "import model\n",
    "\n",
    "import torch\n",
    "\n",
    "import keijzer_exogan as ke\n",
    "\n",
    "# initialize random seeds\n",
    "manualSeed = 999\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"} # Make sure the axis background of plots is white, this is usefull for the black theme in JupyterLab\n",
    "# Initialize default seaborn layout\n",
    "sns.set_palette(sns.hls_palette(8, l=.3, s=.8))\n",
    "sns.set(style='ticks')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Local variables\n",
    "\"\"\"\n",
    "workers = 0 # Number of workers for dataloader, 0 when to_vram is enabled\n",
    "batch_size = 1 # using one image ofcourse\n",
    "image_size = 32\n",
    "nz = 100 # size of latent vector\n",
    "n_iters = 1000 #25*10**3 # number of iterations to do for inpainting\n",
    "torch.backends.cudnn.benchmark=True # Uses udnn auto-tuner to find the best algorithm to use for your hardware, speeds up training by almost 50%\n",
    "\n",
    "lr = 1e-1\n",
    "lamb1 = 1 #1e4\n",
    "lamb2 = 1e-1 # 1 , total_loss = lamb1*loss_context + lamb2*loss_perceptual\n",
    "\n",
    "beta1 = 0.5 # Beta1 hyperparam for Adam optimizers\n",
    "selected_gpus = [2] # Number of GPUs available. Use 0 for CPU mode.\n",
    "\n",
    "#n_images = 500\n",
    "inpaint_n_times = 1\n",
    "\n",
    "save_array_results = True\n",
    "load_array_results = False\n",
    "filename = 'debug_0_500_1_1e-1_gan' # 0:100 lamb1=10, lamb2=1\n",
    "\n",
    "# debug_0_5000_1_1e-1_*      c is exogan data with original brian mask, d is with binary mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/datb/16011015/ExoGAN_data/selection//' #notice how you dont put the last folder in here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load all ASPAs"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "images = np.load(path+'last_chunks_25_percent_images_v4.npy').astype('float32')\n",
    "\n",
    "np.random.shuffle(images)\n",
    "len(images)\n",
    "\n",
    "# np.save(path+'last_chunks_mini_selection.npy', images[:3000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load smaller selection of ASPAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5000 images\n",
      "Batch size:  1\n",
      "Number of GPUs used:  1\n",
      "Number of images:  1\n"
     ]
    }
   ],
   "source": [
    "images = np.load(path+'last_chunks_25_percent_images_v4.1.npy') # 4.1 is a random selection of 5k images\n",
    "print('Loaded %s images' % len(images))\n",
    "\n",
    "print('Batch size: ', batch_size)\n",
    "\n",
    "\n",
    "# Number of training epochs\n",
    "\n",
    "# Learning rate for optimizers\n",
    "ngpu = len(selected_gpus)\n",
    "print('Number of GPUs used: ', ngpu)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Load data and prepare DataLoader\n",
    "\"\"\"\n",
    "shuffle = False\n",
    "\n",
    "if shuffle:\n",
    "    np.random.shuffle(images) # shuffles the images\n",
    "\n",
    "images = images[3739:3740] # 200 should take ~ 11 hours\n",
    "n_images = len(images)\n",
    "#images = images[:int(len(images)*0.005)]\n",
    "print('Number of images: ', n_images)\n",
    "\n",
    "dataset = ke.numpy_dataset(data=images, to_vram=True) # to_vram pins it to all GPU's\n",
    "#dataset = numpy_dataset(data=images, to_vram=True, transform=transforms.Compose([transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])) # to_vram pins it to all GPU's\n",
    "\n",
    "# Create the dataloader\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=workers, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights...\n",
      "Could not load saved weights.\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/jupyterhub/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2918: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Load and setup models\n",
    "\"\"\"\n",
    "# Initialize cuda\n",
    "device = torch.device(\"cuda:\"+str(selected_gpus[0]) if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "\n",
    "# Load models, set to evaluation mode since training is not needed (this also allows batchsize 1 to work with batchnorm2d layers)\n",
    "netG = model.Generator(ngpu).eval().to(device)\n",
    "netD = model.Discriminator(ngpu).eval().to(device)\n",
    "\n",
    "# Apply weights\n",
    "print('Loading weights...')\n",
    "try:\n",
    "    # Load saved weights\n",
    "    netG.load_state_dict(torch.load('gan_data//weights//netG_state_dict0_v4_test', map_location=device)) #net.module..load_... for parallel model , net.load_... for single gpu model\n",
    "    netD.load_state_dict(torch.load('gan_data//weights//netD_state_dict0_v4_test', map_location=device))\n",
    "except:\n",
    "    print('Could not load saved weights.')\n",
    "    sys.exit()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Define input training stuff (fancy this up)\n",
    "\"\"\"\n",
    "G = netG\n",
    "D = netD\n",
    "z = torch.randn(1, nz, 1, 1, requires_grad=True, device=device)\n",
    "\n",
    "# Handle multi-gpu if desired\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    G = nn.DataParallel(G, device_ids=selected_gpus, output_device=device)\n",
    "    D = nn.DataParallel(D, device_ids=selected_gpus, output_device=device)\n",
    "    #z = nn.DataParallel(z, device_ids=selected_gpus, output_device=device)\n",
    "\n",
    "# Setup Adam optimizers for both G and D\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999)) # should be sgd\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "z_tests = [torch.randn(1, nz, 1, 1, device=device) for _ in range(9)]\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(9):\n",
    "    img = G(z_tests[i]).detach().cpu()[0, 0, :, :]\n",
    "    plt.subplot(3,3,i+1)\n",
    "    #scaler = MinMaxScaler((0, 1.2))\n",
    "    #img = scaler.fit_transform(img)\n",
    "    plt.imshow(img, cmap='gray', vmin=-1.2, vmax=1.2)\n",
    "    #plt.imshow(img, cmap='gray')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "img.min(), img.max(), img.mean(), img.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show first 9 selected images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(9):\n",
    "    try:\n",
    "        img = images[i]\n",
    "        plt.subplot(3,3,i+1)\n",
    "        plt.imshow(img[0, :, :], cmap='gray', vmin=-1.2, vmax=1.2)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "img.min(), img.max(), img.mean(), img.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [param.data.cpu().numpy().flatten() for param in netD.parameters()]\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i,layer_weights in enumerate(weights):\n",
    "    print('Layer: %s \\t n_weights: %s \\t std: %.4f \\t mean: %.4f' % (i, len(layer_weights), layer_weights.std(), layer_weights.mean()))\n",
    "    plt.subplot(3,2,i+1)\n",
    "    plt.title('netD layer %s weights' % i)\n",
    "    plt.hist(layer_weights, bins=100)\n",
    "    plt.grid()\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [param.data.cpu().numpy().flatten() for param in netG.parameters()] # where param.data are the weights of the i-th layer\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i,layer_weights in enumerate(weights):\n",
    "    print('Layer: %s \\t n_weights: %s \\t std: %.4f \\t mean: %.4f' % (i, len(layer_weights), layer_weights.std(), layer_weights.mean()))\n",
    "    plt.subplot(3,2,i+1)\n",
    "    plt.title('netG layer %s weights' % i)\n",
    "    plt.hist(layer_weights, bins=100)\n",
    "    plt.grid()\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inpainting\n",
    "The corrupted image $y$ is mapped to the closest $z$ in the latent representation space, this mapping is denoted as $\\hat{z}$.\n",
    "    \n",
    "$\\hat{z} = \\operatorname{arg\\,min}_z \\{ \\mathcal{L}_c(z |y, M) + \\mathcal{L}_p (z) \\}$\n",
    "\n",
    "where\n",
    "\n",
    "$\\mathcal{L}_c(z |y, M) = || M \\bigodot G(z) - M \\bigodot y||_1 = || M \\bigodot (G(z)-y) ||_1 $\n",
    "\n",
    "with $\\mathcal{L}_c$ being contextual loss and $M$ being a binary mask with the same size as $y$,\n",
    "\n",
    "$\\mathcal{L}_p (z) = \\lambda \\operatorname{log}(1-D(G(z)))$\n",
    "\n",
    "with $\\mathcal{L}_p$ being perceptual loss and $D$ being the discriminator.\n",
    "  \n",
    "Once $G(\\hat{z})$ is generated, the final solution $\\hat{x}$ is calculated as\n",
    "\n",
    "$\\hat{x} = \\operatorname{arg\\, min}_x ||\\nabla x - \\nabla G(\\hat{z}) ||^2_2$  \n",
    "\n",
    "(substitute $x_i = y_i$ for $M_i = 1$).\n",
    "\n",
    "-----\n",
    "\n",
    "$|| ... ||$ is done by `torch.norm()`.  \n",
    "$... \\bigodot ...$ is done by `torch.mul()`.  \n",
    "-----\n",
    "TODO: Implement $\\hat{x} = \\operatorname{arg\\, min}_x ||\\nabla x - \\nabla G(\\hat{z}) ||^2_2$    \n",
    "Currently $\\hat{x} = G(\\hat{z}) \\bigodot (1 -M)+y$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask():\n",
    "    \n",
    "    mask = np.full([1,1,32,32], 1) # init array with 0.5's\n",
    "    mask = torch.from_numpy(mask).to(device)\n",
    "    \n",
    "    #mask = torch.ones([1, 1, 32, 32]).to(device) # create mask with 1's in the shape of image\n",
    "    \n",
    "    #print(\"mask.shape\", mask.shape)\n",
    "\n",
    "    # use a random 'easy' mask\n",
    "    \n",
    "    # set all params to 0\n",
    "    mask[:, :, :16, 25:] = 0\n",
    "    \n",
    "    # set noise to 0\n",
    "    mask[:, :, 18:, :] = 0\n",
    "    \n",
    "    \n",
    "    \"\"\"Weighted mask\"\"\"\n",
    "    # Normalization factors\n",
    "    mask[:, :, 16:18, :] = 6  #6\n",
    "    \n",
    "    # Planet mass\n",
    "    mask[:, :, :16, 25:26] = 0\n",
    "    \n",
    "    mask = mask.float() # make sure dtype is float, torch was complaining during inpainting that this is a double\n",
    "    \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = create_mask().cpu()[0, 0, :, :]\n",
    "plt.imshow(m, cmap='gray', vmin=0, vmax=2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inpaiting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_inpainting_results():\n",
    "    # save real aspa's\n",
    "    all_reals = []\n",
    "    for selected_aspa in range(len(real_images)):\n",
    "        reals = np.array([real_images[selected_aspa][i].detach().cpu().numpy()[0, 0, :, :] for i in range(inpaint_n_times)])\n",
    "        all_reals.append(reals)\n",
    "        \n",
    "    all_reals = np.array(all_reals)\n",
    "    \n",
    "    np.save('gan_data//val_errors//'+filename+'_reals.npy', all_reals)\n",
    "    \n",
    "    # save inpained aspa's\n",
    "    all_inpainteds = []\n",
    "    for selected_aspa in range(len(real_images)):\n",
    "        inpainteds = np.array([final_inpainted_images[selected_aspa][i].detach().cpu().numpy()[0, 0, :, :] for i in range(inpaint_n_times)])\n",
    "        all_inpainteds.append(inpainteds)\n",
    "\n",
    "    all_inpainteds = np.array(all_inpainteds)\n",
    "    \n",
    "    np.save('gan_data//val_errors//'+filename+'_inpainteds.npy', all_inpainteds)\n",
    "    \n",
    "    np.save('gan_data//val_errors//'+filename+'_n_iterations.npy', n_iteration)\n",
    "    np.save('gan_data//val_errors//'+filename+'_contextual_losses.npy', contextual_losses)\n",
    "    np.save('gan_data//val_errors//'+filename+'_perceptual_losses.npy', perceptual_losses)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inpainting loop\n",
    "22.33 iters / s "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to keep track of progress\n",
    "real_images = []\n",
    "masked_images= []\n",
    "#inpainted_images = []\n",
    "final_inpainted_images = [] # last n inpainted images, one index location for each input image [[aspa1, aspa1, aspa1], [aspa2,aspa2,aspa2]] .... where aspa1, aspa1, aspa1 are 3 unique inpaintings\n",
    "\n",
    "n_iteration = []\n",
    "perceptual_losses = []\n",
    "contextual_losses = []\n",
    "\n",
    "MSELoss = nn.MSELoss()\n",
    "L1Loss = nn.L1Loss() # MAE\n",
    "SmoothL1Loss = nn.SmoothL1Loss()\n",
    "\n",
    "\"\"\"\n",
    "Inpainting\n",
    "\"\"\"\n",
    "t3 = time.time()\n",
    "past_s_image = 0\n",
    "for i, data in enumerate(dataloader, 0): # batches per epoch\n",
    "    real_images_n_times = []\n",
    "    final_inpainted_images_n_times = [] # list of (n) last inpainted image(s), for one aspa\n",
    "    \n",
    "    t1 = time.time()\n",
    "    \n",
    "    \n",
    "    for j in range(inpaint_n_times): # inpaint n times per image\n",
    "        z = torch.randn(1, nz, 1, 1, requires_grad=True, device=device)\n",
    "        opt = optim.Adam([z], lr=lr)\n",
    "        \n",
    "        real_cpu = data.to(device)\n",
    "        b_size = real_cpu.size(0) # this is one ofc, it's one image we're trying to inpaint\n",
    "\n",
    "        #print(\"data.shape: \", data.shape)\n",
    "        image = data.to(device) # select the image (Channel, Height, Width), this is the original unmasked input image\n",
    "\n",
    "        real_images_n_times.append(image)\n",
    "        #print(\"image.shape: \", image.shape)\n",
    "\n",
    "        \"\"\"Mask the image\"\"\"\n",
    "        mask = create_mask()\n",
    "\n",
    "        masked_image = torch.mul(image, mask).to(device) #image bigodot mask\n",
    "        masked_images.append(masked_image)\n",
    "        #print('masked image shape', masked_image.shape)\n",
    "        #plt.imshow(masked_image.detach().cpu()[0, 0, :, :], cmap='gray') # plot the masked image\n",
    "\n",
    "        # what's v and m?\n",
    "        v = torch.tensor(0, dtype=torch.float32, device=device)\n",
    "        m = torch.tensor(0, dtype=torch.float32, device=device)\n",
    "\n",
    "\n",
    "        \"\"\"Start the inpainting process\"\"\"\n",
    "        early_stopping_n_iters = 0\n",
    "        early_stopping_min_loss = 999999999999 # set to random high number to initialize\n",
    "        \n",
    "        if j != 0:\n",
    "            n_iteration.append(iteration)\n",
    "            \n",
    "        for iteration in range(n_iters):\n",
    "            if z.grad is not None:\n",
    "                z.grad.data.zero_()\n",
    "\n",
    "            G.zero_grad()\n",
    "            D.zero_grad()\n",
    "\n",
    "\n",
    "            image_generated = G(z) # generated image G(z)\n",
    "            image_generated_masked = torch.mul(image_generated, mask) # G(z) bigodot M\n",
    "            image_generated_inpainted = torch.mul(image_generated, (1-mask))+masked_image\n",
    "\n",
    "            #if (iteration % 100 == 0):\n",
    "            #    inpainted_images.append(image_generated_inpainted)\n",
    "\n",
    "            #print(\"image_generated_inpainted.shape : \",image_generated_inpainted.shape)\n",
    "\n",
    "            t = image_generated_inpainted.detach().cpu()[0, 0, :, :]\n",
    "\n",
    "            # TODO: why does this already look real?\n",
    "            #plt.imshow(t, cmap='gray') # plot the masked image \n",
    "\n",
    "            \"\"\"Calculate losses\"\"\"\n",
    "            loss_context = lamb1*torch.norm(image_generated_masked-masked_image, p=1) #what's p=1?\n",
    "            #loss_context = lamb1*MSELoss(image_generated_masked,masked_image)\n",
    "            #loss_context = L1Loss(image_generated_masked, masked_image)*10\n",
    "            #loss_context = SmoothL1Loss(image_generated_masked, masked_image)*10\n",
    "\n",
    "            discriminator_output = netD(image_generated_inpainted) - 0.005 # -0.005 offset so loss_perceptual doesn't become 1 when D(G(z)) == 1.000000\n",
    "            #print(\"Discriminator output: \", discriminator_output)\n",
    "\n",
    "            labels = torch.full((b_size,), 1, device=device)\n",
    "            loss_perceptual = lamb2*torch.log(1-discriminator_output)\n",
    "\n",
    "            #if loss_perceptual == -np.inf:\n",
    "            #    #print('loss perceptual == -np.inf()')\n",
    "            #    loss_perceptual = torch.tensor(-10, dtype=torch.float32, device=device)\n",
    "\n",
    "            #print(loss_perceptual.data.cpu().numpy().flatten()[0])\n",
    "\n",
    "            total_loss = loss_context + loss_perceptual\n",
    "            #total_loss = loss_context + 10*discriminator_output\n",
    "\n",
    "            # grab the values from losses for printing\n",
    "            loss_perceptual = loss_perceptual.data.cpu().numpy().flatten()[0]\n",
    "            #loss_perceptual = 0\n",
    "            loss_context = loss_context.data.cpu().numpy().flatten()[0]\n",
    "\n",
    "\n",
    "\n",
    "            total_loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            total_loss = total_loss.data.cpu().numpy().flatten()[0]\n",
    "\n",
    "            \"\"\"Early stopping\"\"\" # TODO: \n",
    "            if iteration > 0:\n",
    "                delta_loss = early_stopping_min_loss - total_loss\n",
    "                delta_iters = iteration - iter1\n",
    "\n",
    "                if (delta_loss < 0.1) or (total_loss > early_stopping_min_loss):\n",
    "                    early_stopping_n_iters += 1\n",
    "                else:\n",
    "                    #print('set to zero')\n",
    "                    early_stopping_n_iters = 0\n",
    "\n",
    "                if early_stopping_n_iters > 1000:\n",
    "                    #n_iteration.append(iteration)\n",
    "                    #break\n",
    "                    #z = z_best\n",
    "                    #early_stopping_n_iters = 0\n",
    "                    #print('z copied')\n",
    "                    pass\n",
    "\n",
    "            loss1 = total_loss\n",
    "            iter1 = iteration\n",
    "\n",
    "            if total_loss < early_stopping_min_loss:\n",
    "                early_stopping_min_loss = total_loss\n",
    "                best_inpained_image = image_generated.detach().cpu()\n",
    "                contextual_loss_best = loss_context\n",
    "                perceptual_loss_best = loss_perceptual\n",
    "                early_stopping_n_iters = 0\n",
    "                z_best = z\n",
    "                #print('min loss: ', early_stopping_min_loss)\n",
    "\n",
    "            t2 = time.time()\n",
    "\n",
    "            \"\"\"Calculate ETA\"\"\"\n",
    "            #t_per_iter = t2 - t1 # time per iteration in seconds\n",
    "            past_time = t2 - t3\n",
    "            #eta = t_per_iter * (n_iters - iteration) + t_per_iter* (len(images)-i+1) * n_iters # time left to finish epoch/image + time left to finish all epochs/images in SECONDS\n",
    "            #eta_h = (eta/ 60) // 60 # divisor integer\n",
    "            #eta_m = eta % 60 # get remainer\n",
    "            past_m = past_time / 120\n",
    "            past_s = past_time % 60\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            if (iteration % 50 == 0):\n",
    "                print(\"\\r image [{}/{}] inpainting [{}/{}] iteration : {:4} , context_loss: {:.3f}, perceptual_loss: {:3f}, total_loss: {:3f}, min L: {:3f}, {:1f}, D(G(z)): {:3f}, Run time: {:.0f}m {:.0f}s, s per image {:.0f}s\".format(i+1, \n",
    "                len(images), j+1, inpaint_n_times, iteration, loss_context,loss_perceptual, total_loss,early_stopping_min_loss, early_stopping_n_iters, discriminator_output.data.cpu().numpy().flatten()[0], past_m, past_s, past_s_image),end=\"\")\n",
    "\n",
    "\n",
    "\n",
    "            \"\"\"NaN monitor\"\"\"\n",
    "            #if (loss_context or loss_perceptual == np.nan()) and iteration >64:\n",
    "            #    print(r'='*10 + '     NaN     '+ '='*10)\n",
    "            #    print(loss_context, loss_percept  ual)\n",
    "                #break+\n",
    "\n",
    "        final_inpainted_images_n_times.append(best_inpained_image.detach().cpu())\n",
    "    \n",
    "    past_s_image = (t2-t1) % 60\n",
    "    final_inpainted_images.append(final_inpainted_images_n_times)\n",
    "    real_images.append(real_images_n_times)\n",
    "    contextual_losses.append(contextual_loss_best)\n",
    "    perceptual_losses.append(perceptual_loss_best)\n",
    "    \n",
    "    if save_array_results:\n",
    "        save_inpainting_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptual_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error of one ASPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_aspa = 0\n",
    "\n",
    "\n",
    "reals = [real_images[selected_aspa][i].detach().cpu().numpy()[0, 0, :, :] for i in range(inpaint_n_times)]\n",
    "\n",
    "inpainteds = [final_inpainted_images[selected_aspa][i].detach().cpu().numpy()[0, 0, :, :] for i in range(inpaint_n_times)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# :16, :25 is the spectrum location within the ASPA\n",
    "\n",
    "real = reals[0][:16, :25].flatten()\n",
    "inpainted = inpainteds[0][:16, :25].flatten()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(real, 'x-', c='r', linewidth=0.5)\n",
    "plt.plot(inpainted, '.-', linewidth=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pixel difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(inpainted-real, '.-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "xhat,yhat = ke.decode_spectrum_from_aspa(reals[i])\n",
    "x,y  = ke.decode_spectrum_from_aspa(inpainteds[i])\n",
    "\n",
    "plt.plot(xhat, yhat, label='real', c='r')\n",
    "plt.plot(x,y,label='inpainted')\n",
    "\n",
    "plt.gca().set_xscale('log')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reals[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reals = [ke.decode_params_from_aspa(aspa_real) for aspa_real in reals]\n",
    "inpainteds = [ke.decode_params_from_aspa(aspa_inpainted) for aspa_inpainted in inpainteds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ExoGAN params with zero's\n",
    "inpainted_params = {\n",
    "    'planet_mass': [],\n",
    "    'temp_profile': [],\n",
    "    'ch4_mixratio': [],\n",
    "    'planet_radius': [],\n",
    "    'h2o_mixratio': [],\n",
    "    'co2_mixratio': [],\n",
    "    'co_mixratio': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over all params\n",
    "for i,param in enumerate(inpainted_params):\n",
    "    # iterate over all inpainted values (of above param)\n",
    "    for j,inpainted in enumerate(inpainteds):\n",
    "        y_hat = reals[j][param] # real value\n",
    "        y = inpainted[param] # inpainted value\n",
    "        \n",
    "        percentage_error = ((y - y_hat) / y_hat)*100\n",
    "        \n",
    "        inpainted_params[param] += [percentage_error]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(inpainted_params)\n",
    "df = df.replace([np.inf, -np.inf], np.nan) # TODO: Fix the occurance of inf later\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.figure(figsize=((25,10)))\n",
    "for i,param in enumerate(inpainted_params):\n",
    "    #if param == 'temp_profile':\n",
    "    #    pass\n",
    "    #else:\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.title(param)\n",
    "    plt.hist(df[param], bins=25)\n",
    "\n",
    "    # plot mean and median line\n",
    "    mu = df[param].mean()\n",
    "    plt.axvline(x=mu,  color='black', linestyle='-.', alpha=0.9, label='mean')\n",
    "    plt.axvline(x=df[param].median(),  color='black', linestyle='-', alpha=1, label='median')\n",
    "\n",
    "    # plot std lines\n",
    "    plt.axvline(x=mu-df[param].std(),  color='black', linestyle=':', alpha=1, label=r'$\\sigma$')\n",
    "    plt.axvline(x=mu+df[param].std(),  color='black', linestyle=':', alpha=1)\n",
    "\n",
    "    #plt.xlabel(r'Percentage error')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error per ASPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_aspa_error(selected_aspa):\n",
    "    \"\"\"\n",
    "    Index value of selected aspa -> final_inpainted_images[selected_aspa]\n",
    "    E.g. 0 for first image, 1 for 2nd image etc.\n",
    "    \n",
    "    Returns df containing percentage errors per param\n",
    "    \"\"\"\n",
    "    \n",
    "    #if load_array_results:\n",
    "    #    reals = np.load('gan_data//val_errors//'+filename+'_reals.npy')\n",
    "    #    inpainteds = np.load('gan_data//val_errors//'+filename+'_inpainteds.npy')\n",
    "    #else:\n",
    "    reals = [real_images[selected_aspa][i].detach().cpu().numpy()[0, 0, :, :] for i in range(inpaint_n_times)]\n",
    "    inpainteds = [final_inpainted_images[selected_aspa][i].detach().cpu().numpy()[0, 0, :, :] for i in range(inpaint_n_times)]\n",
    "    \n",
    "    reals = [ke.decode_params_from_aspa(aspa_real) for aspa_real in reals]\n",
    "    inpainteds = [ke.decode_params_from_aspa(aspa_inpainted) for aspa_inpainted in inpainteds]\n",
    "\n",
    "    # Initialize ExoGAN params with zero's\n",
    "    inpainted_params = {\n",
    "        'planet_mass': [],\n",
    "        'temp_profile': [],\n",
    "        'ch4_mixratio': [],\n",
    "        'planet_radius': [],\n",
    "        'h2o_mixratio': [],\n",
    "        'co2_mixratio': [],\n",
    "        'co_mixratio': []\n",
    "    }\n",
    "\n",
    "    # iterate over all params\n",
    "    for i,param in enumerate(inpainted_params):\n",
    "        # iterate over all inpainted values (of above param)\n",
    "        for j,inpainted in enumerate(inpainteds):\n",
    "            y_hat = reals[j][param] # real value\n",
    "            y = inpainted[param] # inpainted value\n",
    "\n",
    "            percentage_error = ((y - y_hat) / y_hat)*100\n",
    "\n",
    "            inpainted_params[param] += [percentage_error]\n",
    "\n",
    "    df = pd.DataFrame(inpainted_params)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [calculate_aspa_error(selected_aspa) for selected_aspa in range(len(images))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create df of all mean values\n",
    "Dataframe containing the mean value of the n inpaintings, per image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = []\n",
    "for i in range(len(dfs)):\n",
    "    df = dfs[i].describe()\n",
    "    means.append(df[df.index == 'mean'])\n",
    "    \n",
    "means = pd.concat(means)\n",
    "means = means.replace([np.inf, -np.inf], np.nan) # TODO: Fix the occurance of inf later\n",
    "means.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create df of all std values\n",
    "Dataframe containing the std of the n inpaintings, per image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stds = []\n",
    "for i in range(len(dfs)):\n",
    "    df = dfs[i].describe()\n",
    "    stds.append(df[df.index == 'std'])\n",
    "    \n",
    "stds = pd.concat(stds)\n",
    "stds.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hist of all mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=((25,10)))\n",
    "for i,param in enumerate(inpainted_params):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.title(param)\n",
    "    \n",
    "    try:\n",
    "        plt.hist(means[param], bins=25)\n",
    "        \n",
    "        # plot mean and median line\n",
    "        plt.axvline(x=means[param].mean(),  color='black', linestyle='-.', alpha=0.9)\n",
    "        plt.axvline(x=means[param].median(),  color='black', linestyle='-', alpha=0.9)\n",
    "    \n",
    "        # plot std lines\n",
    "        plt.axvline(x=-means[param].std(),  color='black', linestyle=':', alpha=1)\n",
    "        plt.axvline(x=means[param].std(),  color='black', linestyle=':', alpha=1)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    plt.grid()\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n iterations per inpainting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iteration = np.array(n_iteration)\n",
    "\n",
    "if save_array_results:\n",
    "    np.save('gan_data//val_errors//'+filename+'_n_iterations.npy', n_iteration)\n",
    "\n",
    "_ = plt.hist(n_iteration, bins=50)\n",
    "n_iteration.mean(), n_iteration.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
